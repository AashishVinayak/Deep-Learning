{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: cleaning the text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "# importing nltk\n",
    "import nltk\n",
    "# download nltk data \n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who', 'down', 'further', 'was', 'll', 'couldn', \"that'll\", 'mightn', 'hasn', 'these', 'both', 'other', 'most', 'how', 'will', 'my', 'such', 'so', 'them', 'at', 'their', 'isn', 'they', 'into', 'nor', 'with', 'on', \"it's\", 'but', 'by', 'any', \"you're\", 'her', 'is', 'this', 'where', 'been', 'having', 'can', \"couldn't\", 'themselves', 'him', 'than', 'ours', 've', 'when', \"wasn't\", 'too', 'that', 'off', 'once', 'were', 'have', 'doing', 'didn', 'his', 're', 's', 'am', 'between', 'all', 'm', 'yourselves', 'again', 'before', 'y', \"you'd\", 'does', \"shan't\", 'she', 'should', 'now', 'yourself', 'what', \"she's\", 'few', \"you've\", 'has', 'shouldn', 'about', 'be', 'ain', 'hers', 'myself', 'haven', 'he', 'not', \"hadn't\", 'shan', 'being', \"isn't\", \"needn't\", \"shouldn't\", 'you', 'd', 'won', 'against', 'ma', 'are', 'the', 'itself', 'and', 'over', \"hasn't\", 'only', \"haven't\", 'wasn', 'do', \"aren't\", 'through', 'no', 'it', 'an', 'herself', 'we', 'did', 't', 'then', 'ourselves', 'more', 'from', \"should've\", 'same', 'until', 'those', 'aren', 'here', 'whom', 'very', \"won't\", 'its', 'me', \"don't\", 'our', 'out', 'while', 'hadn', 'why', 'above', 'in', \"wouldn't\", 'there', 'wouldn', 'each', 'needn', 'which', 'mustn', 'for', 'because', 'own', 'under', 'during', 'doesn', 'up', \"you'll\", 'weren', 'below', 'don', \"didn't\", \"doesn't\", 'himself', 'o', 'or', \"weren't\", \"mustn't\", 'yours', 'of', 'as', 'some', 'just', 'your', 'i', 'theirs', 'if', 'to', \"mightn't\", 'a', 'had', 'after']\n"
     ]
    }
   ],
   "source": [
    "# importing the stopwords list\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = list(set(stopwords.words(\"english\")))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (100, 3)\n",
      "columns:  ['id' 'sentiment' 'review']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "data = (pd.read_csv(\"labeledTrainData.tsv\", quoting=3, header=0, delimiter=\"\\t\"))\n",
    "# limiting data to 10000 examples due to lack of computation power\n",
    "data = data[0:100]\n",
    "# data info\n",
    "print(\"data shape: \", data.shape)\n",
    "print(\"columns: \",data.columns.values)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing html markups \n",
    "review = [BeautifulSoup(i, \"html5lib\").getText() for i in data['review'] ]\n",
    "# removing unnecessary characters\n",
    "review = [re.sub(\"[^a-zA-Z']\", \" \", i) for i in review]\n",
    "# converting the text corpus into lower case and splitting\n",
    "review = [i.lower().split() for i in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removing stop words\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if not word in stopwords]\n",
    "    return text\n",
    "\n",
    "# removing stop words\n",
    "for i in range(len(review)):\n",
    "    review[i] = remove_stopwords(review[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating vocabulary\n",
    "vocab = list(set([word for line in review for word in line]))\n",
    "# creating a word to index dictionary; will be useful in one_hot encoding\n",
    "word_to_id = {word:i for i, word in enumerate(vocab)}\n",
    "# creating a index to word dictionary; will be useful in one_hot decoding\n",
    "id_to_word = {i:word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 2: preparing data for word2vec encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# function for one hot encoding\n",
    "def one_hot(text, vocab):\n",
    "    hot_matrix = np.zeros([len(text), len(vocab)])\n",
    "    for i in range(len(text)):\n",
    "        if not text[i] in word_to_id:\n",
    "            hot_matrix[i, 0] = 0\n",
    "        else:\n",
    "            hot_matrix[i, word_to_id[text[i]]] = 1\n",
    "\n",
    "    return hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a very important function\n",
    "\n",
    "def context_words(text, skip):\n",
    "    right = []; left = [];  final = []\n",
    "    for i in range(len(text)):\n",
    "        # words window at the right of the main word\n",
    "        right.append([text[i+s] for s in range(1, skip+1) if (i+s)< len(text)])\n",
    "        # words window at the left of the main word\n",
    "        left.append(list(reversed([text[i-s] for s in range(1, skip+1) if (i-s) >= 0])))\n",
    "        # concatenating final list of context words\n",
    "        final.append(left[i] + right[i])\n",
    "    # filling empty spaces\n",
    "    final[0].insert(0, 'unk')\n",
    "    final[0].insert(1, 'unk')\n",
    "    final[1].insert(0, 'unk')\n",
    "    final[-2].insert(0, 'unk')\n",
    "    final[-1].insert(0, 'unk')\n",
    "    final[-1].insert(1, 'unk')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create sets of input and output data\n",
    "\n",
    "def create_context_batch(text, skip, return_one_hot = False):\n",
    "    # list of context words\n",
    "    context_list = context_words(text, skip)\n",
    "    # lists to hold training set and labels\n",
    "    x = []; y = []\n",
    "    # loop over each index in text\n",
    "    for i in range(len(text)):\n",
    "        # loop over each index inside context_list[i]\n",
    "        for j in context_list[i]:\n",
    "            # training set\n",
    "            x.append(str(text[i]))\n",
    "            # labels\n",
    "            y.append(str(j))\n",
    "    if return_one_hot == True:\n",
    "        x = one_hot(x, vocab)\n",
    "        y = one_hot(y, vocab)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 3: Training  the word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python 3.5.2\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=400, input_dim=4363, activation=None)`\n",
      "  \"\"\"\n",
      "c:\\python 3.5.2\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=4363, input_dim=400, activation=\"sigmoid\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "884/884 [==============================] - 9s 11ms/step - loss: 0.6628 - acc: 0.9067\n",
      "Epoch 2/5\n",
      "884/884 [==============================] - 4s 5ms/step - loss: 0.3784 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "884/884 [==============================] - 4s 4ms/step - loss: 0.0820 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "884/884 [==============================] - 4s 4ms/step - loss: 0.0218 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "884/884 [==============================] - 4s 4ms/step - loss: 0.0115 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0239 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0131 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0081 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "336/336 [==============================] - 1s 4ms/step - loss: 0.0058 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "336/336 [==============================] - 2s 5ms/step - loss: 0.0047 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "960/960 [==============================] - 4s 4ms/step - loss: 0.0103 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "960/960 [==============================] - 4s 4ms/step - loss: 0.0044 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "960/960 [==============================] - 4s 4ms/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "960/960 [==============================] - 4s 4ms/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "960/960 [==============================] - 4s 4ms/step - loss: 0.0025 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "760/760 [==============================] - 3s 4ms/step - loss: 0.0050 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "760/760 [==============================] - 3s 4ms/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "760/760 [==============================] - 3s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "760/760 [==============================] - 3s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "760/760 [==============================] - 3s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "868/868 [==============================] - 4s 5ms/step - loss: 0.0039 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "868/868 [==============================] - 4s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "868/868 [==============================] - 4s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "868/868 [==============================] - 4s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "868/868 [==============================] - 4s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "220/220 [==============================] - 1s 5ms/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "220/220 [==============================] - 1s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "220/220 [==============================] - 1s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "220/220 [==============================] - 1s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "220/220 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "280/280 [==============================] - 1s 5ms/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "280/280 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "280/280 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "376/376 [==============================] - 2s 4ms/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "376/376 [==============================] - 2s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "376/376 [==============================] - 2s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "376/376 [==============================] - 2s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "376/376 [==============================] - 2s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "808/808 [==============================] - 4s 4ms/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "808/808 [==============================] - 4s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "808/808 [==============================] - 4s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "808/808 [==============================] - 4s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "808/808 [==============================] - 4s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0016 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "416/416 [==============================] - 2s 4ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "416/416 [==============================] - 2s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "416/416 [==============================] - 2s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "416/416 [==============================] - 2s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "416/416 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "852/852 [==============================] - 4s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "852/852 [==============================] - 4s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "852/852 [==============================] - 4s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "852/852 [==============================] - 4s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "852/852 [==============================] - 4s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924/924 [==============================] - 4s 4ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "924/924 [==============================] - 4s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "924/924 [==============================] - 4s 5ms/step - loss: 0.0016 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "596/596 [==============================] - 3s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "288/288 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "476/476 [==============================] - 2s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1328/1328 [==============================] - 6s 4ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "1328/1328 [==============================] - 6s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "1328/1328 [==============================] - 6s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "1328/1328 [==============================] - 6s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "1328/1328 [==============================] - 6s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812/812 [==============================] - 3s 4ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "812/812 [==============================] - 3s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "812/812 [==============================] - 3s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "812/812 [==============================] - 3s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "812/812 [==============================] - 3s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "608/608 [==============================] - 3s 4ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "608/608 [==============================] - 3s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "608/608 [==============================] - 3s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "608/608 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "608/608 [==============================] - 3s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "252/252 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "252/252 [==============================] - 1s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "252/252 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 0.9998A: 0s - loss: 0.0021 - acc: 0\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1068/1068 [==============================] - 5s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "1068/1068 [==============================] - 5s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "1068/1068 [==============================] - 5s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "1068/1068 [==============================] - 5s 4ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "1068/1068 [==============================] - 5s 5ms/step - loss: 0.0016 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "540/540 [==============================] - 2s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "540/540 [==============================] - 2s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "540/540 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "540/540 [==============================] - 2s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "540/540 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "344/344 [==============================] - 2s 4ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "344/344 [==============================] - 1s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "344/344 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "344/344 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "344/344 [==============================] - 2s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "340/340 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "340/340 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "340/340 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "392/392 [==============================] - 2s 4ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "392/392 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "392/392 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "392/392 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "392/392 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 1s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1028/1028 [==============================] - 5s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "1028/1028 [==============================] - 5s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "1028/1028 [==============================] - 5s 5ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "1028/1028 [==============================] - 4s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "1028/1028 [==============================] - 5s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "260/260 [==============================] - 1s 4ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "260/260 [==============================] - 1s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "316/316 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "316/316 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "316/316 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "2192/2192 [==============================] - 10s 4ms/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "2192/2192 [==============================] - 10s 4ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "2192/2192 [==============================] - 10s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "2192/2192 [==============================] - 10s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "2192/2192 [==============================] - 10s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 2s 5ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 0.0014 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "244/244 [==============================] - 1s 5ms/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 2/5\n",
      "244/244 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "244/244 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "244/244 [==============================] - 1s 5ms/step - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "244/244 [==============================] - 1s 5ms/step - loss: 0.0013 - acc: 0.9998\n",
      "\n",
      "\n",
      "done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim = 400, activation = None, input_dim = len(vocab)))\n",
    "model.add(Dense(output_dim = len(vocab), activation = 'sigmoid', input_dim = 400 ))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for text in review[0:70]:\n",
    "    # create training and labels\n",
    "    x_train, y_train = create_context_batch(text, 2, return_one_hot = True)\n",
    "    # training \n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    print('\\n\\ndone\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 4: Creating word embeddings on trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting weights and bias for the embedding layer\n",
    "weights = model.get_weights()[0]\n",
    "bias = model.get_weights()[1]\n",
    "\n",
    "# final prediction\n",
    "def get_embedding(text, w, b):\n",
    "    text_input = one_hot(text, vocab)\n",
    "    \n",
    "    embedding = np.dot(text_input, w) + b\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input text: \n",
      "\n",
      "\"\\\"The Classic War of the Worlds\\\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\"critics\\\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\"critics\\\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\"critics\\\" perceive to be its shortcomings.\"\n",
      "\n",
      "\n",
      "word embedding: \n",
      "\n",
      "array([[ 0.19056149,  0.16951014,  0.19253768, ..., -0.19486819,\n",
      "         0.19823901, -0.17729314],\n",
      "       [ 0.19056149,  0.16951014,  0.19253768, ..., -0.19486819,\n",
      "         0.19823901, -0.17729314],\n",
      "       [ 0.19056149,  0.16951014,  0.19253768, ..., -0.19486819,\n",
      "         0.19823901, -0.17729314],\n",
      "       ...,\n",
      "       [ 0.19056149,  0.16951014,  0.19253768, ..., -0.19486819,\n",
      "         0.19823901, -0.17729314],\n",
      "       [ 0.19056149,  0.16951014,  0.19253768, ..., -0.19486819,\n",
      "         0.19823901, -0.17729314],\n",
      "       [ 0.19056149,  0.16951014,  0.19253768, ..., -0.19486819,\n",
      "         0.19823901, -0.17729314]])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "print('input text: \\n')\n",
    "# example\n",
    "print(data['review'][1])\n",
    "# word embedding for the above example\n",
    "embed = get_embedding(data['review'][1], weights, bias)\n",
    "\n",
    "print('\\n\\nword embedding: \\n')\n",
    "pprint(embed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
