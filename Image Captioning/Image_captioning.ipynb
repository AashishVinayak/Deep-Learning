{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image_captioning.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"7TCmGeWhcpix","colab_type":"code","colab":{}},"cell_type":"code","source":["#!pip install gensim\n","import numpy as np\n","import tensorflow as tf\n","import gensim\n","import re\n","from gensim.models import Word2Vec\n","import requests, zipfile, io\n","from PIL import Image\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.layers import Dense, Flatten"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kHabxZ_NjKbS","colab_type":"code","colab":{}},"cell_type":"code","source":["# downloading data\n","image_data_url = \"http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\"\n","text_data_url = \"http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_text.zip\"\n","\n","# downloading images\n","images_from_url = requests.get(image_data_url)\n","# extraction\n","images_zip = zipfile.ZipFile(io.BytesIO(images_from_url.content))\n","images_zip.extractall()\n","\n","# downloading captions\n","text_from_url = requests.get(text_data_url)\n","# extraction\n","text_zip = zipfile.ZipFile(io.BytesIO(text_from_url.content))\n","text_zip.extractall()\n","\n","!rm -r __MACOSX"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GfC8T4OQE8lM","colab_type":"code","colab":{}},"cell_type":"code","source":["### Preparing metadata\n","\n","# respective captions\n","captions = open(\"Flickr8k.token.txt\").read()\n","\n","# some processing magic\n","captions = captions.split(\"\\n\")\n","captions = [i.split(\"\\t\") for i in captions]\n","\n","# removing (.)\n","for c in range(len(captions)-1):\n","    captions[c][1] = ' '.join(re.findall(r'\\w+[a-zA-Z]', captions[c][1]))\n","    \n","\n","# cleaning up the image names\n","for j in range(len(captions)):\n","    captions[j][0] = captions[j][0][0:len(captions[j][0])-2]\n","\n","    \n","# this dictionary holds the image names and respective captions\n","meta_data = {}\n","for i in range(0, len(captions)-1, 5):\n","    meta_data[captions[i][0]] = [captions[i+j][1] for j in range(5)]\n","    \n","# sample\n","i = 0\n","for m in meta_data.keys():\n","    print(m, \":\")\n","    print(meta_data[m], \"\\n\")\n","    i+=1\n","    if i==3:break\n","\n","# removing a bad key\n","del(meta_data[\"2258277193_586949ec62.jpg.1\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w52z8kS1a-BT","colab_type":"code","colab":{}},"cell_type":"code","source":["embedding_len = 200          # length of word vector\n","\n","### making word embedding\n","# to do this we'll loop over all the sentences in the whole dataset and make word vectors out of it using gensim\n","\n","# this list will hold all the sentences \n","sentences = []\n","\n","for key in meta_data.keys():\n","    for s in meta_data[key]:\n","        sentences.append(s.split())\n","        \n","# training the word2vec model\n","embedding = Word2Vec(sentences, size=embedding_len, min_count=0, window=4, sg=1, workers=20)\n","embedding.train(sentences, total_examples=len(sentences), epochs = 10)\n","\n","# demo\n","embedding.wv.most_similar(\"entry\", topn=3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9C_965nQNs3y","colab_type":"code","colab":{}},"cell_type":"code","source":["### Placeholders\n","x_train = tf.placeholder(tf.float32, [None, embedding_len])\n","y_train = tf.placeholder(tf.float32, [None, embedding_len])\n","x_img = tf.placeholder(tf.float32, [None, 224, 224, 3])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M_K2IgVauGvO","colab_type":"code","colab":{}},"cell_type":"code","source":["def GRU(n_h, n_em, a_t, x, w = None, init=False, t=0):\n","    \"\"\"\n","        n_h    : no. of neurons in GRU hidden layer\n","        n_em   : length of embedding vector\n","        a_t    : hidden state vector\n","        x      : word vector input\n","        w      : weights\n","        init   : whether to initialize weights \n","        t      : time step\n","    \"\"\"\n","    \n","    if init == True:\n","        tf.reset_default_graph()\n","        # layer 1\n","        w1_rx = tf.get_variable('w1_rx', [n_h, n_em], initializer=tf.contrib.layers.xavier_initializer())\n","        w1_ra = tf.get_variable('w1_ra', [n_h, n_h], initializer=tf.contrib.layers.xavier_initializer())\n","        b1_r  = tf.get_variable('b1_r', [n_h, 1], initializer=tf.contrib.layers.xavier_initializer())\n","    \n","        w1_ux = tf.get_variable('w1_ux', [n_h, n_em], initializer=tf.contrib.layers.xavier_initializer())\n","        w1_ua  = tf.get_variable('w1_ua', [n_h, n_h], initializer=tf.contrib.layers.xavier_initializer())\n","        b1_u   = tf.get_variable('b1_u', [n_h, 1], initializer=tf.contrib.layers.xavier_initializer())\n","\n","        w1_cx  = tf.get_variable('w1_cx', [n_h, n_em], initializer=tf.contrib.layers.xavier_initializer())\n","        w1_ca  = tf.get_variable('w1_ca', [n_h, n_h], initializer=tf.contrib.layers.xavier_initializer())\n","        b1_c   = tf.get_variable('b1_c', [n_h, 1], initializer=tf.contrib.layers.xavier_initializer())\n","\n","        w1_y   = tf.get_variable('w1_y', [n_em, n_h], initializer=tf.contrib.layers.xavier_initializer())\n","        b1_y   = tf.get_variable('b1_y', [n_em, 1], initializer=tf.contrib.layers.xavier_initializer())\n","        \n","        # layer 2\n","        w2_rx = tf.get_variable('w2_rx', [n_h, n_em], initializer=tf.contrib.layers.xavier_initializer())\n","        w2_ra = tf.get_variable('w2_ra', [n_h, n_h], initializer=tf.contrib.layers.xavier_initializer())\n","        b2_r  = tf.get_variable('b2_r', [n_h, 1], initializer=tf.contrib.layers.xavier_initializer())\n","    \n","        w2_ux = tf.get_variable('w2_ux', [n_h, n_em], initializer=tf.contrib.layers.xavier_initializer())\n","        w2_ua  = tf.get_variable('w2_ua', [n_h, n_h], initializer=tf.contrib.layers.xavier_initializer())\n","        b2_u   = tf.get_variable('b2_u', [n_h, 1], initializer=tf.contrib.layers.xavier_initializer())\n","\n","        w2_cx  = tf.get_variable('w2_cx', [n_h, n_em], initializer=tf.contrib.layers.xavier_initializer())\n","        w2_ca  = tf.get_variable('w2_ca', [n_h, n_h], initializer=tf.contrib.layers.xavier_initializer())\n","        b2_c   = tf.get_variable('b2_c', [n_h, 1], initializer=tf.contrib.layers.xavier_initializer())\n","\n","        w2_y   = tf.get_variable('w2_y', [n_em, n_h], initializer=tf.contrib.layers.xavier_initializer())\n","        b2_y   = tf.get_variable('b2_y', [n_em, 1], initializer=tf.contrib.layers.xavier_initializer())\n","   \n","\n","    # word vector at step t\n","    x_t = tf.reshape(x[t], [x.shape[1],1])\n","    a_t = tf.reshape(a_t, [a_t.shape[1],1])\n","    \n","    # gru layer 1    \n","    reset1 = tf.nn.sigmoid( tf.matmul(w1_rx, x_t) + tf.matmul(w1_ra, a_t) + b1_r )\n","    update1 = tf.nn.sigmoid( tf.matmul(w1_ux, x_t) + tf.matmul(w1_ua, a_t) + b1_u )\n","    cell1 = tf.nn.tanh( tf.matmul(w1_cx, x_t) + tf.matmul(w1_ca, tf.multiply(reset1,a_t)) + b1_c )\n","    h1 = tf.multiply(update1, a_t) + tf.multiply((1-update1), cell)\n","    yhat1 = tf.nn.softmax(tf.matmul(w1_y, h1) + b1_y)\n","    \n","    # gru layer 2\n","    reset2 = tf.nn.sigmoid( tf.matmul(w2_rx, x_t) + tf.matmul(w2_ra, a_t) + b2_r )\n","    update2 = tf.nn.sigmoid( tf.matmul(w2_ux, x_t) + tf.matmul(w2_ua, a_t) + b2_u )\n","    cell2 = tf.nn.tanh( tf.matmul(w2_cx, x_t) + tf.matmul(w2_ca, tf.multiply(reset2,a_t)) + b2_c )\n","    h2 = tf.multiply(update2, a_t) + tf.multiply((1-update2), cell)\n","    yhat2 = tf.nn.softmax(tf.matmul(w2_y, h1) + b2_y)\n","    \n","    #if t <= x.shape[0]:\n","     #   GRU(n_size = n_size, a_t = h2, x = yhat, w=w, t = t+1)\n","    \n","    return yhat"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e8XFzyhY6hPP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"5df389e7-b6d5-4c18-e482-ffd419d582dd","executionInfo":{"status":"ok","timestamp":1539690393744,"user_tz":-330,"elapsed":4155,"user":{"displayName":"Aashish Vinayak","photoUrl":"","userId":"11492081867973563164"}}},"cell_type":"code","source":["# using VGG16 for the image classifier(encoder)\n","\n","with tf.device('/gpu:0'):\n","    vgg = VGG16(include_top=False, weights='imagenet', input_tensor=x_img, input_shape=(224,224,3))\n","    encoder = vgg.output\n","    encoder = Dense(1024, activation=\"relu\")(encoder)\n","    encoder = Flatten()(encoder)\n","    encoder = Dense(512, activation=\"tanh\")(encoder)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"8ZiKGdDJ1CFs","colab_type":"code","colab":{}},"cell_type":"code","source":["GRU(100, n_em = 200, a_t=encoder, x = x_train, init=True, t=0)"],"execution_count":0,"outputs":[]}]}