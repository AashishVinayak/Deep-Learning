{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############   TOOK ME 10 MINUTES TO RUN THE TRAINING LOOP FOR 1 EPOCH :| FOLLOWED BY A CRASH   ##############\n",
    "###   P.S. I have an AMD GPU and intel core i3 4th gen @ 1.7GHz with 4 GB RAM\n",
    "###   Can't do much about it, its expensive, I'm just a student....\n",
    "###   But the code is good if I could run it I would have done some more debugging.....\n",
    "'''\n",
    "    classifying cat or not a cat using an AUTOENCODER CNN on Tensorflow\n",
    "    Dataset: Cat and Dog classes from Cifar-10 Dataset\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating minibatches\n",
    "def mini_batch(X, size):\n",
    "    idx = np.random.randint(len(X), size = (size,1))\n",
    "    x_bat = X[idx]\n",
    "    x_bat = x_bat.reshape(size, 32, 32, 3)\n",
    "    \n",
    "    return x_bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function adds gaussian noise in the images for the purpose of training\n",
    "def create_noise(image):\n",
    "    noisy = np.array(tf.random_normal(shape = tf.shape(image), mean = 0, stddev = 0, dtype = tf.float32))\n",
    "    return image + noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported  5000 images!\n"
     ]
    }
   ],
   "source": [
    "# labels\n",
    "labels = pd.DataFrame(pd.read_csv('trainlabels.csv'))\n",
    "# importing 5000 images of size 32x32x3\n",
    "i = 0\n",
    "img_base = []\n",
    "for img in glob.glob(\"train\\\\*.png\"):\n",
    "    if labels['label'][i] == 'cat':\n",
    "        img_base.append(cv2.imread(img))        \n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1\n",
    "        continue\n",
    "    \n",
    "print('imported ', len(img_base), 'images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  (4000, 32, 32, 3)\n",
      "testing data:  (1000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# dataset preparation\n",
    "x_train = np.array(img_base[0:4000]).astype(np.float32)\n",
    "x_test  = np.array(img_base[4000:]).astype(np.float32)\n",
    "print(\"training data: \", x_train.shape)\n",
    "print(\"testing data: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating placeholder for input image data\n",
    "inputs = tf.placeholder(tf.float32, (None, 32,32,3))\n",
    "target = tf.placeholder(tf.float32, (None, 32,32,3))\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder unit\n",
    "c1 = tf.layers.conv2d(inputs, filters = 32, kernel_size = (3,3), padding = 'same', activation = tf.nn.relu)\n",
    "m1 = tf.layers.max_pooling2d(c1, strides = (2,2), pool_size = (2,2), padding = \"same\")\n",
    "# m1 shape = 16 x 16 x 32\n",
    "c2 = tf.layers.conv2d(m1, filters = 32, kernel_size = (3,3), padding = 'same', activation = tf.nn.relu)\n",
    "m2 = tf.layers.max_pooling2d(c2, strides = (2,2), pool_size = (2,2), padding = \"same\")\n",
    "# m2 shape = 8 x 8 x 32\n",
    "c3 = tf.layers.conv2d(m2, filters = 32, kernel_size = (3,3), padding = 'same', activation = tf.nn.relu)\n",
    "encoded = tf.layers.max_pooling2d(c3, strides = (2,2), pool_size = (2,2), padding = \"same\")\n",
    "# encoded shape = 4 x 4 x 32\n",
    "\n",
    "# decoder unit\n",
    "d1 = tf.image.resize_images(encoded, size = (8,8), method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "c4 = tf.layers.conv2d(d1, filters = 16, kernel_size = (3,3), padding = 'same', activation = tf.nn.relu)\n",
    "\n",
    "d2 = tf.image.resize_images(encoded, size = (16,16), method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "c5 = tf.layers.conv2d(d2, filters = 32, kernel_size = (3,3), padding = 'same', activation = tf.nn.relu)\n",
    "\n",
    "d3 = tf.image.resize_images(encoded, size = (32,32), method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "c6 = tf.layers.conv2d(d3, filters = 32, kernel_size = (3,3), padding = 'same', activation = tf.nn.relu)\n",
    "\n",
    "logits = tf.layers.conv2d(c6, filters = 3, kernel_size = (32,32), padding = 'same', activation = None)\n",
    "\n",
    "# passing the reconstructed image in sigmoid\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "\n",
    "# sigmoid cross entropy is the loss function\n",
    "cost_func = tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = inputs)\n",
    "optimize = tf.train.AdamOptimizer(learning_rate).minimize(cost_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#########    Run this block only if you have computation power    ##########\n",
    "\n",
    "# creating a tensorflow session\n",
    "s = tf.Session()\n",
    "s.run(tf.global_variables_initializer())\n",
    "# hyperparameters\n",
    "epochs = 0                                 #######   Change This to any number ONLY if you have a cool NVIDIA GPU\n",
    "\n",
    "# training loop\n",
    "for i in range(epochs):\n",
    "    train_batch = mini_batch(x_train, 100)\n",
    "    noise_batch = np.array(create_noise(train_batch))\n",
    "    s.run(optimize, {inputs : noise_batch, target : train_batch})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
